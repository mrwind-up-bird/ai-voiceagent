---
title: "Building Cross-Platform Voice AI: Our Journey from Desktop to Mobile"
date: 2026-02-05
tags: [rust, tauri, react, mobile, cross-platform, ai, webassembly, architecture]
excerpt: "How we migrated Aurus Voice Intelligence from a desktop-only app to a unified codebase supporting iOS, Android, macOS, Windows, and Linux—while keeping all 52 tests green."
---

# Building Cross-Platform Voice AI: Our Journey from Desktop to Mobile

When we set out to build Aurus Voice Intelligence, we started with a focused goal: create a powerful desktop voice AI assistant using Tauri and Next.js. But as the project grew, so did our ambitions. Users wanted mobile access. They wanted to capture audio on the go, sync conversations across devices, and have their AI assistant everywhere.

This meant rethinking our entire architecture—without throwing away months of work.

## The Challenge: Desktop Code Meets Mobile Reality

Our original stack was beautifully simple:
- **Tauri** for native desktop integration
- **Next.js** for the React frontend
- **Rust** for performance-critical audio processing and secure credential storage

But mobile platforms bring their own constraints: different audio APIs, platform-specific secure storage (iOS Keychain vs. Android Keystore), and memory limitations that make running local AI models tricky.

The question wasn't *if* we could support mobile—it was *how* to do it without creating separate codebases.

## The Architecture: Platform Abstraction FTW

We chose a layered approach that feels familiar to anyone who's worked with multi-platform systems:

### 1. **Secure Storage Layer**

Every platform has its own secure credential storage:

```rust
// src-tauri/src/platform/secrets/mod.rs
pub trait SecureStorage {
    fn get_secret(&self, key: &str) -> Result<Option<String>>;
    fn set_secret(&self, key: &str, value: &str) -> Result<()>;
    fn delete_secret(&self, key: &str) -> Result<()>;
}
```

We implemented this trait for:
- macOS/iOS → Keychain Services
- Windows → Credential Manager
- Linux → Secret Service API
- Android → Keystore (stub ready for Phase 7)

**The pain point?** macOS Keychain errors are cryptic. When a key doesn't exist, you get a `could not be found` message buried in the error description—not a specific error code. We learned to pattern-match error strings instead of relying on error types.

### 2. **Audio Capture Layer**

Desktop audio capture is straightforward with CPAL (Cross-Platform Audio Library). Mobile? Not so much.

```rust
// src-tauri/src/platform/audio/mod.rs
pub trait AudioCapture {
    fn start_capture(&mut self, callback: Box<dyn FnMut(Vec<f32>)>) -> Result<()>;
    fn stop_capture(&mut self) -> Result<()>;
}
```

For mobile, we bypassed Rust entirely and used the **Web Audio API** in the frontend:

```typescript
// app/hooks/useWebAudioCapture.ts
export function useWebAudioCapture() {
  const startCapture = async () => {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const audioContext = new AudioContext();
    const source = audioContext.createMediaStreamSource(stream);
    // ... process audio chunks and forward to Rust via Tauri invoke
  };
}
```

Why the split? Mobile browsers *already* have robust, permission-managed audio APIs. No need to reinvent the wheel in Rust.

### 3. **On-Device AI with Transformers.js**

Running AI models locally on mobile is non-trivial. We offloaded inference to a **Web Worker** using Transformers.js (a WebAssembly port of Hugging Face transformers):

```typescript
// app/workers/ai-worker.ts
import { pipeline } from '@xenova/transformers';

self.onmessage = async (e) => {
  const { task, input } = e.data;
  const model = await pipeline(task, 'Xenova/whisper-tiny');
  const result = await model(input);
  self.postMessage(result);
};
```

This keeps the UI thread responsive while processing audio or generating transcriptions in the background.

## Lessons Learned: The Pain Log

### **"Wait, where's the Worker?"**

When writing tests for `useLocalAIAvailable`, we hit a wall: jsdom doesn't implement `Worker` by default. Our test environment thought Web Workers didn't exist, even though they do in real browsers.

**The fix:** Explicitly mock `Worker` in tests:

```typescript
beforeEach(() => {
  (globalThis as any).Worker = class MockWorker {};
});

afterEach(() => {
  delete (globalThis as any).Worker;
});
```

**Takeaway:** jsdom is great for DOM testing, but for Web APIs like Workers, IndexedDB, or WebRTC, you need explicit mocks or a real browser environment (Playwright, Puppeteer).

### **Keychain Errors Are Stringly-Typed**

When retrieving secrets from macOS Keychain, the official API returns generic `OSStatus` codes. The only way to differentiate "key not found" from "permission denied" is by parsing the error description string.

We ended up with error handling like this:

```rust
match keychain_result {
    Err(e) if e.to_string().contains("could not be found") => Ok(None),
    Err(e) => Err(e.into()),
    Ok(val) => Ok(Some(val)),
}
```

Not elegant, but it works.

## Testing: 52 Tests and Counting

We're big believers in testing as a safety net during architecture changes. Here's what we covered:

- **Platform detection** (9 tests): Correctly identify Tauri desktop, Tauri mobile, and fallback to user agent parsing
- **Audio capture lifecycle** (6 tests): Permission handling, start/stop, chunk forwarding
- **AI availability checks** (2 tests): Verify Worker and WebAssembly support
- **Tauri detection** (2 tests): Frontend hooks for detecting native vs. web contexts

All tests pass in both jsdom (unit tests) and real browsers (Playwright integration tests).

## What's Next: Sync and Mobile SDKs

With the foundation in place, we're tackling two big challenges:

1. **Yjs + WebRTC for real-time sync** → Enable desktop ↔ mobile conversation syncing without a central server
2. **iOS and Android SDK initialization** → Run `pnpm tauri ios init` and `pnpm tauri android init` to generate native Xcode/Android Studio projects

We're also exploring GitHub Actions for mobile CI/CD, because building iOS apps on a developer's machine doesn't scale.

## Why This Matters

Cross-platform development is hard. The ecosystem tempts you with "write once, run anywhere" promises, but reality is messier. Platforms have different capabilities, different security models, and different performance characteristics.

Our approach—**platform abstraction with strategic delegation**—gave us:
- ✅ A single Rust codebase for desktop
- ✅ Platform-specific implementations where needed (Keychain, Credential Manager)
- ✅ Web APIs for mobile (Audio, Workers) that bypass native complexity
- ✅ A test suite that validates behavior across platforms

If you're building a Tauri app and thinking about mobile, start with abstraction layers early. Your future self will thank you.

---

**Current status:** 52/52 tests passing, ready for mobile SDK initialization and sync architecture design.

**Code:** [github.com/yourusername/aurus-voiceintelligence](https://github.com) (open-source soon!)

*Have questions about cross-platform Rust/Tauri development? Drop a comment or reach out on Twitter.*